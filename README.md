В данной лабораторной работе используем пример полносвязной нейронной сети из 5 слоёв. 
Сначала добавляем Flatten-слой, сглаживающий входящие данные. Далее используем пять слоёв Dense: 2 слоя на 128 нейронов, еще 2 слоя на 64 нейрона и слой на 10 нейронов. Первые 4 Dense слоя используют активацию 'relu', последний - 'softmax'.

При обучении нейронной сети происходит 10 этапов обучения, при этом в цикле обучения используются:
* оптимизатор 'adam'
* функция потерь 'sparse_categorical_crossentropy'
* метрика 'accuracy'

Графики метрики точности и функции потерь:
![Accuracy](https://i.ibb.co/Sx3dj5V/1.jpg)
![Loss](https://i.ibb.co/kXJqcXY/2.jpg)

Графики метрики точности и функции потерь на валидационной выборке:
![Val Accuracy](https://i.ibb.co/T8sCF6P/3.jpg)
![Val Loss](https://i.ibb.co/SmQ28kW/4.jpg)